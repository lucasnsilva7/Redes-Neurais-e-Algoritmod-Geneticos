{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monstrinho 3.5 - Forma, função e ativação\n",
    "\n",
    "#### Enunciado \n",
    "\n",
    "Objetivo: implemente 3 novas funções de ativação na rede neural feita em Python\n",
    "puro nos vídeos da disciplina. Escreva brevemente sobre estas 3 funções de ativação,\n",
    "mostrando a equação delas e comentando a diferença com relação à função de ativação\n",
    "sigmoidal. Mostre que seu código funciona rodando alguns testes simples.\n",
    "\n",
    "Comentário: aqui não é o lugar de inventar funções de ativação. Busque por funções\n",
    "de ativação já existentes utilizadas em redes neurais.\n",
    "\n",
    "Comentário 2: observe que o enunciado diz claramente que é para realizar a tarefa\n",
    "na rede neural feita em Python puro nos vídeos da disciplina. Se você está usando o\n",
    "PyTorch, numpy, tensorflow, keras, lightning ou qualquer outra biblioteca pronta,\n",
    "você está no caminho errado!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Valor:\n",
    "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
    "        self.data = data\n",
    "        self.progenitor = progenitor\n",
    "        self.operador_mae = operador_mae\n",
    "        self.rotulo = rotulo\n",
    "        self.grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Valor(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self + outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data + outro_valor.data\n",
    "        operador_mae = \"+\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_adicao():\n",
    "            self.grad += resultado.grad\n",
    "            outro_valor.grad += resultado.grad\n",
    "            \n",
    "        resultado.propagar = propagar_adicao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __mul__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self * outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data * outro_valor.data\n",
    "        operador_mae = \"*\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_multiplicacao():\n",
    "            self.grad += resultado.grad * outro_valor.data # grad_filho * derivada filho em relação a mãe\n",
    "            outro_valor.grad += resultado.grad * self.data\n",
    "            \n",
    "        resultado.propagar = propagar_multiplicacao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"Realiza a operação: exp(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.exp(self.data)\n",
    "        operador_mae = \"exp\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_exp():\n",
    "            self.grad += resultado.grad * data \n",
    "        \n",
    "        resultado.propagar = propagar_exp\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __pow__(self, expoente):\n",
    "        \"\"\"Realiza a operação: self ** expoente\"\"\"\n",
    "        assert isinstance(expoente, (int, float))\n",
    "        progenitor = (self, )\n",
    "        data = self.data ** expoente\n",
    "        operador_mae = f\"**{expoente}\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_pow():\n",
    "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
    "        \n",
    "        resultado.propagar = propagar_pow\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __truediv__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self / outro_valor\"\"\"\n",
    "        return self * outro_valor ** (-1)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Realiza a operação: -self\"\"\"\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self - outro_valor\"\"\"\n",
    "        return self + (-outro_valor)\n",
    "    \n",
    "    def __radd__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: outro_valor + self\"\"\"\n",
    "        return self + outro_valor\n",
    "    \n",
    "    def __rmul__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: outro_valor * self\"\"\"\n",
    "        return self * outro_valor\n",
    "    \n",
    "    def sig(self):\n",
    "        \"\"\"Realiza a operação: exp(self) / (exp(self) + 1)\"\"\"\n",
    "        return self.exp() / (self.exp() + 1)\n",
    "    \n",
    "    def propagar(self):\n",
    "        pass\n",
    "    \n",
    "    def propagar_tudo(self):\n",
    "        \n",
    "        self.grad = 1\n",
    "        \n",
    "        ordem_topologica = []\n",
    "        \n",
    "        visitados = set()\n",
    "\n",
    "        def constroi_ordem_topologica(v):\n",
    "            if v not in visitados:\n",
    "                visitados.add(v)\n",
    "                for progenitor in v.progenitor:\n",
    "                    constroi_ordem_topologica(progenitor)\n",
    "                ordem_topologica.append(v)\n",
    "\n",
    "        constroi_ordem_topologica(self)\n",
    "        \n",
    "        for vertice in reversed(ordem_topologica):\n",
    "            vertice.propagar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Neuronio:\n",
    "    def __init__(self, num_dados_entrada):\n",
    "        self.vies = Valor(random.uniform(-1, 1))\n",
    "        \n",
    "        self.pesos = []\n",
    "        for i in range(num_dados_entrada):\n",
    "            self.pesos.append(Valor(random.uniform(-1, 1)))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        assert len(x) == len(self.pesos)\n",
    "        \n",
    "        soma = 0\n",
    "        for info_entrada, peso_interno in zip(x, self.pesos):\n",
    "            soma += info_entrada * peso_interno\n",
    "            \n",
    "        soma += self.vies  \n",
    "        dado_de_saida = soma.sig()\n",
    "        \n",
    "        return dado_de_saida       \n",
    "    \n",
    "    def parametros(self):\n",
    "        return self.pesos + [self.vies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camada:\n",
    "    def __init__(self, num_neuronios, num_dados_entrada):\n",
    "        neuronios = []\n",
    "        \n",
    "        for _ in range(num_neuronios):\n",
    "            neuronio = Neuronio(num_dados_entrada)\n",
    "            neuronios.append(neuronio)\n",
    "            \n",
    "        self.neuronios = neuronios     \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dados_de_saida = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            informacao = neuronio(x)\n",
    "            dados_de_saida.append(informacao)\n",
    "            \n",
    "        if len(dados_de_saida) == 1:\n",
    "            return dados_de_saida[0]\n",
    "        else:        \n",
    "            return dados_de_saida  \n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            params_neuronio = neuronio.parametros()\n",
    "            params.extend(params_neuronio)\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, num_dados_entrada, num_neuronios_por_camada):\n",
    "        \n",
    "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
    "        \n",
    "        camadas = []\n",
    "        \n",
    "        for i in range(len(num_neuronios_por_camada)):\n",
    "            camada = Camada(num_neuronios_por_camada[i], percurso[i])\n",
    "            camadas.append(camada)\n",
    "            \n",
    "        self.camadas = camadas\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for camada in self.camadas:\n",
    "            x = camada(x)\n",
    "        return x\n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for camada in self.camadas:\n",
    "            parametros_camada = camada.parametros()\n",
    "            params.extend(parametros_camada)\n",
    "            \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DADOS_DE_ENTRADA = 3  \n",
    "NUM_DADOS_DE_SAIDA = 1    \n",
    "CAMADAS_OCULTAS = [3, 2]  \n",
    "\n",
    "arquitetura_da_rede = CAMADAS_OCULTAS + [NUM_DADOS_DE_SAIDA]\n",
    "\n",
    "minha_mlp = MLP(NUM_DADOS_DE_ENTRADA, arquitetura_da_rede)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, 1.0, -1.0],\n",
    "]\n",
    "\n",
    "y_true = [1, 0, 0.2, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8998617226650142\n",
      "1 0.7338170237773902\n",
      "2 0.6349230275859578\n",
      "3 0.5914594514298834\n",
      "4 0.5747803105909879\n",
      "5 0.5683196416126554\n",
      "6 0.5655306217421049\n",
      "7 0.5640645683697543\n",
      "8 0.5630822362762218\n",
      "9 0.562278299018547\n",
      "10 0.5615393149958013\n",
      "11 0.5608221001553659\n",
      "12 0.5601095747133286\n",
      "13 0.5593944607568115\n",
      "14 0.5586731905046075\n",
      "15 0.5579436113110371\n",
      "16 0.5572041156745347\n",
      "17 0.5564533092033601\n",
      "18 0.5556898823890578\n",
      "19 0.5549125597800061\n",
      "20 0.5541200786275136\n",
      "21 0.5533111788156917\n",
      "22 0.5524845971718628\n",
      "23 0.5516390635387242\n",
      "24 0.5507732976156412\n",
      "25 0.5498860061934799\n",
      "26 0.5489758806417573\n",
      "27 0.5480415945964526\n",
      "28 0.5470818018318122\n",
      "29 0.5460951343139526\n",
      "30 0.5450802004409617\n",
      "31 0.5440355834782566\n",
      "32 0.5429598402010142\n",
      "33 0.5418514997581266\n",
      "34 0.5407090627746055\n",
      "35 0.5395310007116612\n",
      "36 0.5383157555058132\n",
      "37 0.5370617395102925\n",
      "38 0.5357673357636005\n",
      "39 0.5344308986113013\n",
      "40 0.5330507547078525\n",
      "41 0.5316252044254353\n",
      "42 0.530152523696167\n",
      "43 0.5286309663126838\n",
      "44 0.5270587667097085\n",
      "45 0.5254341432457386\n",
      "46 0.523755301999271\n",
      "47 0.5220204410878873\n",
      "48 0.5202277555109499\n",
      "49 0.5183754425075138\n",
      "50 0.5164617074102875\n",
      "51 0.5144847699640637\n",
      "52 0.5124428710630344\n",
      "53 0.5103342798459145\n",
      "54 0.5081573010710159\n",
      "55 0.5059102826755972\n",
      "56 0.503591623405367\n",
      "57 0.5011997803813542\n",
      "58 0.49873327645309146\n",
      "59 0.496190707169791\n",
      "60 0.49357074718569044\n",
      "61 0.4908721559027805\n",
      "62 0.48809378214454263\n",
      "63 0.48523456764897654\n",
      "64 0.48229354916891837\n",
      "65 0.4792698589732723\n",
      "66 0.4761627235550368\n",
      "67 0.4729714603715869\n",
      "68 0.46969547247018495\n",
      "69 0.4663342408876323\n",
      "70 0.46288731475780764\n",
      "71 0.4593542991149499\n",
      "72 0.45573484044433515\n",
      "73 0.45202861010584916\n",
      "74 0.4482352858403261\n",
      "75 0.44435453166389394\n",
      "76 0.4403859765624667\n",
      "77 0.4363291925174623\n",
      "78 0.43218367252510004\n",
      "79 0.4279488094152348\n",
      "80 0.4236238764308049\n",
      "81 0.419208010693679\n",
      "82 0.4147002008532116\n",
      "83 0.4100992803838069\n",
      "84 0.40540392815746507\n",
      "85 0.4006126780522807\n",
      "86 0.39572393944857864\n",
      "87 0.3907360304850893\n",
      "88 0.3856472258665135\n",
      "89 0.38045582079432966\n",
      "90 0.375160212195585\n",
      "91 0.3697589978131368\n",
      "92 0.36425109286878116\n",
      "93 0.3586358629114185\n",
      "94 0.3529132701415668\n",
      "95 0.34708402903092894\n",
      "96 0.34114976555390664\n",
      "97 0.3351131729928524\n",
      "98 0.328978156287225\n",
      "99 0.3227499564967556\n",
      "100 0.31643524733257955\n",
      "101 0.3100421969759605\n",
      "102 0.30358049049794394\n",
      "103 0.29706131087353127\n",
      "104 0.290497279427897\n",
      "105 0.2839023590198172\n",
      "106 0.2772917248239012\n",
      "107 0.27068160784770434\n",
      "108 0.2640891152592176\n",
      "109 0.2575320295608669\n",
      "110 0.25102858637096204\n",
      "111 0.24459722902686756\n",
      "112 0.2382563383028147\n",
      "113 0.23202393773275173\n",
      "114 0.22591737917689583\n",
      "115 0.2199530184880827\n",
      "116 0.2141458960465165\n",
      "117 0.20850944011587694\n",
      "118 0.20305521145189745\n",
      "119 0.19779270516226327\n",
      "120 0.19272922106131715\n",
      "121 0.1878698077825583\n",
      "122 0.18321727989304984\n",
      "123 0.17877230211359135\n",
      "124 0.1745335309711901\n",
      "125 0.1704978018866022\n",
      "126 0.16666034867748447\n",
      "127 0.16301504249665807\n",
      "128 0.15955463808839127\n",
      "129 0.15627101672453647\n",
      "130 0.15315541708305752\n",
      "131 0.1501986474608845\n",
      "132 0.14739127488011144\n",
      "133 0.14472378867846192\n",
      "134 0.1421867379370105\n",
      "135 0.13977084350728025\n",
      "136 0.13746708642658473\n",
      "137 0.13526677517094304\n",
      "138 0.13316159453668794\n",
      "139 0.13114363902913925\n",
      "140 0.12920543353722977\n",
      "141 0.1273399438493199\n",
      "142 0.1255405792700084\n",
      "143 0.12380118927098309\n",
      "144 0.1221160557798512\n",
      "145 0.12047988239857865\n",
      "146 0.11888778155914942\n",
      "147 0.1173352603741878\n",
      "148 0.11581820572670817\n",
      "149 0.1143328689656374\n",
      "150 0.11287585043075767\n",
      "151 0.11144408392004673\n",
      "152 0.11003482113152588\n",
      "153 0.10864561605799661\n",
      "154 0.10727430928358861\n",
      "155 0.10591901212272353\n",
      "156 0.10457809055142771\n",
      "157 0.10325014890399026\n",
      "158 0.1019340133404501\n",
      "159 0.10062871512777585\n",
      "160 0.09933347381532691\n",
      "161 0.09804768041904237\n",
      "162 0.09677088075526544\n",
      "163 0.09550275908162506\n",
      "164 0.09424312220764915\n",
      "165 0.0929918842317198\n",
      "166 0.0917490520447678\n",
      "167 0.09051471171685714\n",
      "168 0.0892890158532503\n",
      "169 0.0880721719746218\n",
      "170 0.08686443194457659\n",
      "171 0.08566608243885304\n",
      "172 0.08447743642621237\n",
      "173 0.08329882561200527\n",
      "174 0.08213059378202024\n",
      "175 0.08097309097619457\n",
      "176 0.07982666841841737\n",
      "177 0.07869167412907734\n",
      "178 0.07756844915020931\n",
      "179 0.07645732431814053\n",
      "180 0.07535861752459651\n",
      "181 0.07427263141363004\n",
      "182 0.07319965146799881\n",
      "183 0.07213994444440139\n",
      "184 0.07109375712210014\n",
      "185 0.0700613153338329\n",
      "186 0.06904282325154742\n",
      "187 0.06803846290243477\n",
      "188 0.06704839389309397\n",
      "189 0.06607275332150889\n",
      "190 0.06511165585799561\n",
      "191 0.06416519397745266\n",
      "192 0.0632334383262268\n",
      "193 0.0623164382077507\n",
      "194 0.061414222171874686\n",
      "195 0.060526798693552285\n",
      "196 0.059654156927267284\n",
      "197 0.05879626752432948\n",
      "198 0.05795308350093334\n",
      "199 0.05712454114566372\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCAS = 200\n",
    "TAXA_DE_APRENDIZADO = 0.5\n",
    "\n",
    "for epoca in range(NUM_EPOCAS):\n",
    "    # forward pass\n",
    "    y_pred = []\n",
    "    for exemplo in x:\n",
    "        previsao = minha_mlp(exemplo)\n",
    "        y_pred.append(previsao)\n",
    "\n",
    "    # loss\n",
    "    erros = []\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        residuo = yp - yt\n",
    "        erro_quadratico = residuo ** 2\n",
    "        erros.append(erro_quadratico)        \n",
    "    loss = sum(erros)\n",
    "\n",
    "    # zero grad\n",
    "    for p in minha_mlp.parametros():\n",
    "        p.grad = 0\n",
    "\n",
    "    # backpropagation\n",
    "    loss.propagar_tudo()\n",
    "\n",
    "    # atualiza parâmetros\n",
    "    for p in minha_mlp.parametros():\n",
    "        p.data = p.data - p.grad * TAXA_DE_APRENDIZADO\n",
    "\n",
    "    # mostra resultado (opcional)\n",
    "    print(epoca, loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
