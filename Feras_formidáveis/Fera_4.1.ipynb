{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fera formidável 4.1 - \" Quem classifica a classe classificadora?\"\n",
    "\n",
    "Alunos: José Victor da Silva Izidório e Lucas Nascimento da Silva\n",
    "\n",
    "#### Enunciado\n",
    "\n",
    "Objetivo: altere a modelo neural feita em Python puro para resolver um problema de\n",
    "classificação. Treine uma modelo neural em um dataset simples de classificação para mostrar\n",
    "que funciona.\n",
    "\n",
    "Comentário: aqui é necessário se informar sobre as diferenças de uma modelo neural\n",
    "classificadora com relação a uma modelo neural regressora. A função de perda, por exemplo,\n",
    "não poderá ser mais a função de perda dos resíduos quadrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução\n",
    "\n",
    "Para adaptar a modelo neural para um problema de classificação o ponto de partida inicial é adaptar a classe Valor para fazer duas novas funções: \n",
    "\n",
    "* Adicionar a função de ativação ReLU e adicionar uam forma de ativar quando queremos usar a função ReLU. A função de ativação ReLU é definida como: \n",
    "\n",
    "$$\n",
    "\\mathrm{ReLU}(x) = \n",
    "\\begin{cases}\n",
    "0, & \\text{se } x < 0 \\\\\n",
    "x, & \\text{se } x \\geq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Existe algumas vantagens em utilizar a função ReLU no lugar da sigmoid, como a maior simplicidade para calcular e evitar que os valores vão para os extremos ficando muito próximos a zero e dificultando o cálculo dos gradientes. \n",
    " \n",
    "* Calcular logaritmo para fazer o cálculo da função de perda CrossEntropy. \n",
    "\n",
    "Além de adaptar a classe Valor, foi necessário definir uma função para calcular a função de perda CrossEntropy. Definida como:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{binária}}(y, \\hat{y}) = - \\left[ y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y}) \\right]\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "$y$ = Valor real \n",
    "\n",
    "$\\hat{y}$ = Valor previsto\n",
    "\n",
    "A segunda adaptação que fizemos foi apenas aplicar o OneHotEncoder nos dados de classificação para colocá-los na modelo neural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Fera_4_1_classes import Valor, Neuronio, Camada, MLP, cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>TA</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>ASY</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>Normal</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>ASY</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>Normal</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>LVH</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>NAP</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>Normal</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age ChestPainType  RestingBP  Cholesterol RestingECG  MaxHR  HeartDisease\n",
       "0     40           ATA        140          289     Normal    172             0\n",
       "1     49           NAP        160          180     Normal    156             1\n",
       "2     37           ATA        130          283         ST     98             0\n",
       "3     48           ASY        138          214     Normal    108             1\n",
       "4     54           NAP        150          195     Normal    122             0\n",
       "..   ...           ...        ...          ...        ...    ...           ...\n",
       "913   45            TA        110          264     Normal    132             1\n",
       "914   68           ASY        144          193     Normal    141             1\n",
       "915   57           ASY        130          131     Normal    115             1\n",
       "916   57           ATA        130          236        LVH    174             1\n",
       "917   38           NAP        138          175     Normal    173             0\n",
       "\n",
       "[918 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data_Frames/heart.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando OneHotEncoder nas colunas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ChestPainType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChestPainType = df[\"ChestPainType\"]\n",
    "\n",
    "ChestPainType = ChestPainType.values.reshape(-1, 1)\n",
    " \n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoder.fit(ChestPainType)\n",
    " \n",
    "ChestPainType_onehot = encoder.transform(ChestPainType)\n",
    "\n",
    "column_names = encoder.get_feature_names_out([\"ChestPainType\"])\n",
    "df_onehot_pain = pd.DataFrame(ChestPainType_onehot, columns=column_names)\n",
    "\n",
    "df = df.drop(columns=[\"ChestPainType\"])\n",
    "\n",
    "df = pd.concat([df, df_onehot_pain], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RestingECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "RestingECG = df[\"RestingECG\"]\n",
    "\n",
    "RestingECG = RestingECG.values.reshape(-1, 1)\n",
    " \n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoder.fit(RestingECG)\n",
    " \n",
    "RestingECG_onehot = encoder.transform(RestingECG)\n",
    "\n",
    "column_names = encoder.get_feature_names_out([\"RestingECG\"])\n",
    "df_onehot_resting = pd.DataFrame(RestingECG_onehot, columns=column_names)\n",
    "\n",
    "df = df.drop(columns=[\"RestingECG\"])\n",
    "\n",
    "df = pd.concat([df, df_onehot_resting], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>ChestPainType_ASY</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>ChestPainType_NAP</th>\n",
       "      <th>ChestPainType_TA</th>\n",
       "      <th>RestingECG_LVH</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  RestingBP  Cholesterol  MaxHR  HeartDisease  ChestPainType_ASY  \\\n",
       "0     40        140          289    172             0                0.0   \n",
       "1     49        160          180    156             1                0.0   \n",
       "2     37        130          283     98             0                0.0   \n",
       "3     48        138          214    108             1                1.0   \n",
       "4     54        150          195    122             0                0.0   \n",
       "..   ...        ...          ...    ...           ...                ...   \n",
       "913   45        110          264    132             1                0.0   \n",
       "914   68        144          193    141             1                1.0   \n",
       "915   57        130          131    115             1                1.0   \n",
       "916   57        130          236    174             1                0.0   \n",
       "917   38        138          175    173             0                0.0   \n",
       "\n",
       "     ChestPainType_ATA  ChestPainType_NAP  ChestPainType_TA  RestingECG_LVH  \\\n",
       "0                  1.0                0.0               0.0             0.0   \n",
       "1                  0.0                1.0               0.0             0.0   \n",
       "2                  1.0                0.0               0.0             0.0   \n",
       "3                  0.0                0.0               0.0             0.0   \n",
       "4                  0.0                1.0               0.0             0.0   \n",
       "..                 ...                ...               ...             ...   \n",
       "913                0.0                0.0               1.0             0.0   \n",
       "914                0.0                0.0               0.0             0.0   \n",
       "915                0.0                0.0               0.0             0.0   \n",
       "916                1.0                0.0               0.0             1.0   \n",
       "917                0.0                1.0               0.0             0.0   \n",
       "\n",
       "     RestingECG_Normal  RestingECG_ST  \n",
       "0                  1.0            0.0  \n",
       "1                  1.0            0.0  \n",
       "2                  0.0            1.0  \n",
       "3                  1.0            0.0  \n",
       "4                  1.0            0.0  \n",
       "..                 ...            ...  \n",
       "913                1.0            0.0  \n",
       "914                1.0            0.0  \n",
       "915                1.0            0.0  \n",
       "916                0.0            0.0  \n",
       "917                1.0            0.0  \n",
       "\n",
       "[918 rows x 12 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = df.drop(columns=[\"HeartDisease\"]).values\n",
    "saidas = df[\"HeartDisease\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo os dados em treino, teste e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANHO_TESTE_E_VALIDACAO = 0.1 \n",
    "\n",
    "# Alocando 10% dos dados para teste\n",
    "entradas_temp, entradas_teste, saidas_temp, saidas_teste = train_test_split(\n",
    "    entradas, saidas, test_size=TAMANHO_TESTE_E_VALIDACAO, random_state=36)\n",
    "\n",
    "# Alocando 10% dos dados para validação\n",
    "entradas_treino, entradas_val, saidas_treino, saidas_val = train_test_split(\n",
    "    entradas_temp, saidas_temp, test_size=TAMANHO_TESTE_E_VALIDACAO, random_state=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = MinMaxScaler()\n",
    "entradas_treino = normalizador.fit_transform(entradas_treino)\n",
    "entradas_val = normalizador.transform(entradas_val)\n",
    "entradas_teste = normalizador.transform(entradas_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando a modelo neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 000 — Perda Treino: 0.6904 | Perda Validação: 0.6828\n",
      "Época 001 — Perda Treino: 0.6887 | Perda Validação: 0.6812\n",
      "Época 002 — Perda Treino: 0.6872 | Perda Validação: 0.6798\n",
      "Época 003 — Perda Treino: 0.6857 | Perda Validação: 0.6784\n",
      "Época 004 — Perda Treino: 0.6843 | Perda Validação: 0.6771\n",
      "Época 005 — Perda Treino: 0.6830 | Perda Validação: 0.6757\n",
      "Época 006 — Perda Treino: 0.6818 | Perda Validação: 0.6744\n",
      "Época 007 — Perda Treino: 0.6805 | Perda Validação: 0.6728\n",
      "Época 008 — Perda Treino: 0.6791 | Perda Validação: 0.6711\n",
      "Época 009 — Perda Treino: 0.6775 | Perda Validação: 0.6694\n",
      "Época 010 — Perda Treino: 0.6756 | Perda Validação: 0.6676\n",
      "Época 011 — Perda Treino: 0.6736 | Perda Validação: 0.6656\n",
      "Época 012 — Perda Treino: 0.6714 | Perda Validação: 0.6631\n",
      "Época 013 — Perda Treino: 0.6686 | Perda Validação: 0.6601\n",
      "Época 014 — Perda Treino: 0.6655 | Perda Validação: 0.6573\n",
      "Época 015 — Perda Treino: 0.6624 | Perda Validação: 0.6542\n",
      "Época 016 — Perda Treino: 0.6588 | Perda Validação: 0.6502\n",
      "Época 017 — Perda Treino: 0.6546 | Perda Validação: 0.6451\n",
      "Época 018 — Perda Treino: 0.6500 | Perda Validação: 0.6398\n",
      "Época 019 — Perda Treino: 0.6456 | Perda Validação: 0.6346\n",
      "Época 020 — Perda Treino: 0.6415 | Perda Validação: 0.6296\n",
      "Época 021 — Perda Treino: 0.6376 | Perda Validação: 0.6251\n",
      "Época 022 — Perda Treino: 0.6340 | Perda Validação: 0.6209\n",
      "Época 023 — Perda Treino: 0.6307 | Perda Validação: 0.6169\n",
      "Época 024 — Perda Treino: 0.6275 | Perda Validação: 0.6131\n"
     ]
    }
   ],
   "source": [
    "epocas = 1000\n",
    "taxa_aprendizado = 0.1\n",
    "modelo = MLP(num_entradas=11, tamanhos_ocultos=[3, 2, 1])\n",
    "\n",
    "for epoca in range(epocas):\n",
    "    # Previsões no conjunto de treino\n",
    "    saidas_preditas_treino = []\n",
    "    for amostra in entradas_treino:\n",
    "        entrada_valores = [Valor(x) for x in amostra]\n",
    "        saidas_preditas_treino.append(modelo(entrada_valores))\n",
    "    \n",
    "    # Calcular perda\n",
    "    perda_treino = cross_entropy(saidas_treino.flatten(), saidas_preditas_treino)\n",
    "\n",
    "    # Zerar gradientes e faz backpropagation\n",
    "    for p in modelo.params():\n",
    "        p.grad = 0.0\n",
    "    perda_treino.backward()\n",
    "\n",
    "    # Atualizar pesos\n",
    "    for p in modelo.params():\n",
    "        p.data -= taxa_aprendizado * p.grad\n",
    "\n",
    "    # Validação\n",
    "    saidas_preditas_val = []\n",
    "    for amostra in entradas_val:\n",
    "        entrada_valores = [Valor(x) for x in amostra]\n",
    "        saidas_preditas_val.append(modelo(entrada_valores))\n",
    "    perda_val = cross_entropy(saidas_val.flatten(), saidas_preditas_val)\n",
    "\n",
    "    print(f\"Época {epoca:03d} — Perda Treino: {perda_treino.data:.4f} | Perda Validação: {perda_val.data:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando a modelo neural para dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perda teste: 0.6731\n"
     ]
    }
   ],
   "source": [
    "saidas_preditas_teste = []\n",
    "for amostra in entradas_teste:\n",
    "    entrada_teste = [Valor(x) for x in amostra]\n",
    "    saidas_preditas_teste.append(modelo(entrada_teste))\n",
    "\n",
    "perda_teste = cross_entropy(saidas_teste.flatten(), saidas_preditas_teste)\n",
    "\n",
    "print(f\"Perda teste: {perda_teste.data:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "A rede neural adaptada para resolver problemas de classificação mostrou-se muito útil, a capaciade de ter um modelo poderoso que consegue prever dados de classificação é de grande utilidade para diversas áreas, como a área da saúde com esse dataset que faz uma previsão em relação a uma doença cardíaca ou até mesmo em outras áreas da ciência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências\n",
    "\n",
    "Cross-entropy. Disponível em: <https://en.wikipedia.org/wiki/Cross-entropy>.\n",
    "\n",
    "CECCON, D. Funções de ativação: definição, características, e quando usar cada uma – IA Expert Academy. Disponível em: <https://iaexpert.academy/2020/05/25/funcoes-de-ativacao-definicao-caracteristicas-e-quando-usar-cada-uma/>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
